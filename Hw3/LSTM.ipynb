{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, Conv2D, Bidirectional\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'd', 1: 'a', 2: 'S', 3: 'b', 4: '3', 5: 'N', 6: 'I', 7: 'V', 8: 'H', 9: 's', 10: '&', 11: 'B', 12: 'G', 13: 'r', 14: ',', 15: 'W', 16: 'F', 17: 'h', 18: 'v', 19: 'i', 20: 'n', 21: 'f', 22: ' ', 23: 'y', 24: \"'\", 25: 'D', 26: 'q', 27: 'R', 28: 'Y', 29: 'e', 30: 'j', 31: 'J', 32: 'L', 33: 'M', 34: 'Z', 35: '!', 36: 'X', 37: 'w', 38: 'p', 39: ':', 40: '?', 41: '.', 42: '-', 43: 'K', 44: 'C', 45: 'A', 46: 'U', 47: 'g', 48: 'P', 49: '$', 50: 'z', 51: 'Q', 52: 'k', 53: '\\n', 54: 'm', 55: 'O', 56: 'T', 57: 'o', 58: 'E', 59: 'u', 60: 'c', 61: ';', 62: 'x', 63: 'l', 64: 't'}\n"
     ]
    }
   ],
   "source": [
    "data_url = 'shakespeare.txt'\n",
    "with io.open(data_url, 'r', encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "vocab = set(text)\n",
    "vocab_to_int = {c:i for i , c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "print(int_to_vocab)\n",
    "train_data = np.array([vocab_to_int[c] for c in text], dtype=np.int32)\n",
    "label = train_data[1:]\n",
    "train_data = train_data[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "chars = 65\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, 65)),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(65, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n",
      "Total chars: 56\n",
      "Number of sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    ")\n",
    "with io.open(path, encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(maxlen)\n",
    "print(len(chars))\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
