{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_loss(train_loss):\n",
    "    t = range(len(train_loss))\n",
    "    plt.plot(t, train_loss, label='BPC')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_learning_curve(train_acc, val_acc):\n",
    "    t = range(len(train_acc))\n",
    "    plt.plot(t, train_acc, label='train')\n",
    "    plt.plot(t, val_acc, label='val')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(seq_length, text_as_int, BATCH_SIZE = 1, BUFFER_SIZE = 10000):\n",
    "    # Create training examples / targets\n",
    "    char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "    sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "    dataset = sequences.map(split_input_target)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "    DATASET_SIZE = len(list(dataset))\n",
    "    train_size = int(0.9 * DATASET_SIZE)\n",
    "    val_size = int(0.1 * DATASET_SIZE)\n",
    "    train_dataset = dataset.take(train_size)\n",
    "    val_dataset = dataset.skip(train_size)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_RNN_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim,batch_input_shape=[batch_size, None]))\n",
    "    model.add(tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, stateful=True))\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_LSTM_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim,batch_input_shape=[batch_size, None]))\n",
    "    model.add(tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True))\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    path_to_file = 'shakespeare.txt'\n",
    "    text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "    vocab = sorted(set(text))\n",
    "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "    idx2char = np.array(vocab)\n",
    "    text_as_int = np.array([char2idx[c] for c in text])\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'shakespeare.txt'\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "vocab = sorted(set(text))\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024,100\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 9938 steps, validate for 1105 steps\n",
      "Epoch 1/10\n",
      "9938/9938 [==============================] - 515s 52ms/step - loss: 1.6464 - val_loss: 1.3991\n",
      "Epoch 2/10\n",
      "9938/9938 [==============================] - 471s 47ms/step - loss: 1.3833 - val_loss: 1.3060\n",
      "Epoch 3/10\n",
      "9938/9938 [==============================] - 437s 44ms/step - loss: 1.3247 - val_loss: 1.2555\n",
      "Epoch 4/10\n",
      "9938/9938 [==============================] - 422s 42ms/step - loss: 1.2855 - val_loss: 1.2220\n",
      "Epoch 5/10\n",
      "9938/9938 [==============================] - 337s 34ms/step - loss: 1.2587 - val_loss: 1.1965\n",
      "Epoch 6/10\n",
      "9938/9938 [==============================] - 333s 34ms/step - loss: 1.2414 - val_loss: 1.1938\n",
      "Epoch 7/10\n",
      "9938/9938 [==============================] - 425s 43ms/step - loss: 1.2302 - val_loss: 1.1871\n",
      "Epoch 8/10\n",
      "9938/9938 [==============================] - 432s 43ms/step - loss: 1.2244 - val_loss: 1.1805\n",
      "Epoch 9/10\n",
      "9938/9938 [==============================] - 432s 43ms/step - loss: 1.2236 - val_loss: 1.1858\n",
      "Epoch 10/10\n",
      "9938/9938 [==============================] - 432s 43ms/step - loss: 1.2264 - val_loss: 1.1886\n",
      "9938/9938 [==============================] - 209s 21ms/step - loss: 1.1887\n",
      "1105/1105 [==============================] - 25s 22ms/step - loss: 1.1860\n",
      "JULIET:\n",
      "It was, the rest,\n",
      "With fidder curses sorenve, sir.\n",
      "\n",
      "PROSPERO:\n",
      "All afterations kindly leaving, and your ruin ta,\n",
      "But shall I promise her by and her attempt.\n",
      "\n",
      "LEONTES:\n",
      "Let them after this eventst Cominius,'\n",
      "and hitness lolled from my bony, my mother, good York,\n",
      "And that your needen cousin Clarence do,\n",
      "Witness you see, that the metal, a divide in them,\n",
      "And therefo all heavents they trust on her humour,\n",
      "They cannot be, God gracious grown healt obearly all,\n",
      "Against us at this dimbling that I speak to you.\n",
      "Nay, good my friends! Trembrions,\n",
      "Ere I have his founds of me, my lord,\n",
      "She's till not make a suffiction, and trive\n",
      "Themself discomdants in prison both waters; pray\n",
      "Your tyracts!\n",
      "\n",
      "CAMILLO:\n",
      "Nan, didst not master tell; most\n",
      "should d forth: here ladys and we are the English day,\n",
      "What: le, when he deserves? myself see her; and am I not\n",
      "Had some smiles what? thou liest, begun\n",
      "And take or goodness of agake gaw'd too!\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "You have known as like for yea. So, my lord;\n",
      "And the impress\n",
      "-----------------------\n",
      "1024,50\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 19683 steps, validate for 2187 steps\n",
      "Epoch 1/10\n",
      "19683/19683 [==============================] - 519s 26ms/step - loss: 1.6642 - val_loss: 1.4539\n",
      "Epoch 2/10\n",
      "19683/19683 [==============================] - 516s 26ms/step - loss: 1.4487 - val_loss: 1.3858\n",
      "Epoch 3/10\n",
      "19683/19683 [==============================] - 517s 26ms/step - loss: 1.4050 - val_loss: 1.3489\n",
      "Epoch 4/10\n",
      "19683/19683 [==============================] - 517s 26ms/step - loss: 1.3809 - val_loss: 1.3341\n",
      "Epoch 5/10\n",
      "19683/19683 [==============================] - 516s 26ms/step - loss: 1.3659 - val_loss: 1.3238\n",
      "Epoch 6/10\n",
      "19683/19683 [==============================] - 520s 26ms/step - loss: 1.3574 - val_loss: 1.3177\n",
      "Epoch 7/10\n",
      "19683/19683 [==============================] - 515s 26ms/step - loss: 1.3521 - val_loss: 1.3221\n",
      "Epoch 8/10\n",
      "19683/19683 [==============================] - 517s 26ms/step - loss: 1.3491 - val_loss: 1.3124\n",
      "Epoch 9/10\n",
      "19683/19683 [==============================] - 519s 26ms/step - loss: 1.3507 - val_loss: 1.3205\n",
      "Epoch 10/10\n",
      "19683/19683 [==============================] - 531s 27ms/step - loss: 1.3540 - val_loss: 1.3249\n",
      "19683/19683 [==============================] - 256s 13ms/step - loss: 1.3266\n",
      "2187/2187 [==============================] - 30s 14ms/step - loss: 1.3218\n",
      "JULIET:\n",
      "Mistress Marcius, and wrong'd the disturb,\n",
      "And his natural wearing complesity?\n",
      "O, \n",
      "Signior Gremio, here be seen, nor his ends and weary he serubusing,\n",
      "And oldly pluck'd in this signse; and that vingman! Then perfurch,\n",
      "Vincy thence by Earl ere her heart?\n",
      "\n",
      "CORIOLANUS:\n",
      "Love Angelo the suionable,\n",
      "Luke but comes me stretch'd for fear;\n",
      "And er is a minister. Let me gently\n",
      "An efather in his outward gride the stroken best.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Go tell you thanks, I saw a falcing.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Cousin, I say; no\n",
      "for death! well, sir; then,--\n",
      "\n",
      "TRANIO:\n",
      "I know by your ears with his arms: talk, let's say, my master's wretch.\n",
      "\n",
      "First Citizen:\n",
      "Marciving every sir, at the trust as hands in?\n",
      "\n",
      "Provost:\n",
      "And now the causes\n",
      "At it be wisching;\n",
      "That you, a guosition. Prithee, gentle sir. Play beginning,\n",
      "And make the gentleman that Cliffor: the king have not been.\n",
      "\n",
      "YORK:\n",
      "That have been, being longed and noted slaughter, gentleman:\n",
      "How fares this news\n",
      "Will have all up\n",
      "The pile art, for the whichshiph sense the\n",
      "-----------------------\n",
      "512,100\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (1, None, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 65)             33345     \n",
      "=================================================================\n",
      "Total params: 1,624,897\n",
      "Trainable params: 1,624,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 9938 steps, validate for 1105 steps\n",
      "Epoch 1/10\n",
      "9938/9938 [==============================] - 165s 17ms/step - loss: 1.6810 - val_loss: 1.4452\n",
      "Epoch 2/10\n",
      "9938/9938 [==============================] - 162s 16ms/step - loss: 1.4217 - val_loss: 1.3521\n",
      "Epoch 3/10\n",
      "9938/9938 [==============================] - 163s 16ms/step - loss: 1.3665 - val_loss: 1.3215\n",
      "Epoch 4/10\n",
      "9938/9938 [==============================] - 163s 16ms/step - loss: 1.3350 - val_loss: 1.2974\n",
      "Epoch 5/10\n",
      "9938/9938 [==============================] - 163s 16ms/step - loss: 1.3136 - val_loss: 1.2729\n",
      "Epoch 6/10\n",
      "9938/9938 [==============================] - 163s 16ms/step - loss: 1.2987 - val_loss: 1.2525\n",
      "Epoch 7/10\n",
      "9938/9938 [==============================] - 163s 16ms/step - loss: 1.2882 - val_loss: 1.2512\n",
      "Epoch 8/10\n",
      "9938/9938 [==============================] - 163s 16ms/step - loss: 1.2799 - val_loss: 1.2375\n",
      "Epoch 9/10\n",
      "9938/9938 [==============================] - 164s 16ms/step - loss: 1.2734 - val_loss: 1.2376\n",
      "Epoch 10/10\n",
      "9938/9938 [==============================] - 163s 16ms/step - loss: 1.2689 - val_loss: 1.2381\n",
      "9938/9938 [==============================] - 80s 8ms/step - loss: 1.2402\n",
      "1105/1105 [==============================] - 10s 9ms/step - loss: 1.2359\n",
      "JULIET:\n",
      "I warrant our hearts thither in the malm\n",
      "At going imphore to this queen, what doth he\n",
      "The old thithand dam, or mask;\n",
      "Upon my honouries will will ortain'ds,\n",
      "Perfoced son, but laster embrais ET:\n",
      "Then 'tis more right:' and Mist an affection tears,\n",
      "Because's and love, and the world's rough:\n",
      "But, cold prithe, powers to be, sound for God's heart.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "I may marry, you're go wife:\n",
      "Stay, and death have done a purpose, requires me.\n",
      "I'll render me partnence; sweet but repentity,\n",
      "For the deed? I have share Pariuse of my tale,\n",
      "What fiery lovers honour.\n",
      "\n",
      "GLOUCESTER:\n",
      "He that lack such as he to the castle:\n",
      "Nervandon, Tupir Juliet, I thank you k:\n",
      "Within too coldgy weeps and invuctor love.\n",
      "\n",
      "DORSET:\n",
      "I have retired to fire: rot from me shumble thar fa' come:\n",
      "You will far our austime lip neaker perilause save:\n",
      "Thou hadst been my poor word, is it meet them to die this foul terms\n",
      "And come of this night, of\n",
      "which the adversy, fair and will any hour for this state, and\n",
      "nit themself, the turtly c\n",
      "-----------------------\n",
      "512,50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (1, None, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 65)             33345     \n",
      "=================================================================\n",
      "Total params: 1,624,897\n",
      "Trainable params: 1,624,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 19683 steps, validate for 2187 steps\n",
      "Epoch 1/10\n",
      "19683/19683 [==============================] - 215s 11ms/step - loss: 1.6780 - val_loss: 1.4906\n",
      "Epoch 2/10\n",
      "19683/19683 [==============================] - 212s 11ms/step - loss: 1.4779 - val_loss: 1.4325\n",
      "Epoch 3/10\n",
      "19683/19683 [==============================] - 213s 11ms/step - loss: 1.4378 - val_loss: 1.4014\n",
      "Epoch 4/10\n",
      "19683/19683 [==============================] - 212s 11ms/step - loss: 1.4179 - val_loss: 1.3822\n",
      "Epoch 5/10\n",
      "19683/19683 [==============================] - 213s 11ms/step - loss: 1.4037 - val_loss: 1.3779\n",
      "Epoch 6/10\n",
      "19683/19683 [==============================] - 213s 11ms/step - loss: 1.3963 - val_loss: 1.3750\n",
      "Epoch 7/10\n",
      "19683/19683 [==============================] - 213s 11ms/step - loss: 1.3929 - val_loss: 1.3655\n",
      "Epoch 8/10\n",
      "19683/19683 [==============================] - 213s 11ms/step - loss: 1.3913 - val_loss: 1.3669\n",
      "Epoch 9/10\n",
      "19683/19683 [==============================] - 213s 11ms/step - loss: 1.3897 - val_loss: 1.3781\n",
      "Epoch 10/10\n",
      "19683/19683 [==============================] - 214s 11ms/step - loss: 1.3897 - val_loss: 1.3748\n",
      "19683/19683 [==============================] - 102s 5ms/step - loss: 1.3743\n",
      "2187/2187 [==============================] - 13s 6ms/step - loss: 1.3759\n",
      "JULIET:\n",
      "And, by your judgmently, as sound;\n",
      "And so it must rend these same age.\n",
      "This in the house, which should not pardon.\n",
      "Nay, quick you, take this time take ive you or good of the poxpove man.\n",
      "Stand with Lord of York, Warwick is one, all my hearts.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Lean proclamation, I sp: yet my foe turn within\n",
      "prayerly notwoman: but seen thou.\n",
      "To cate all this intendom how they so recooved now of the house do olk and good have remanless'd sound.\n",
      "\n",
      "Content: and beautifully again.\n",
      "\n",
      "ROMEO:\n",
      "Ay, ay, from so looks.\n",
      "\n",
      "PAULINA:\n",
      "Remember cause were run a same. Leature 'Will\n",
      "He and remember is bleather: but my life\n",
      "Hath not we wink the lips prove art: farewell, gillain Hour\n",
      "Ferit of our not are to make a scate of Ronger, in these yeads, I mean with him.\n",
      "\n",
      "CLARENCE:\n",
      "A young one thee have a maid ind our blushion\n",
      "Master duty with ye, and she not\n",
      "hum obseived age, best\n",
      "And three patient,\n",
      "When the abundance tedo well forward and show no more dishonourable to part me: that there destine nothe Gentleman:\n",
      "I'\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "total_loss = []\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "seq_len = 100\n",
    "BATCH_SIZE = 1\n",
    "BUFFER_SIZE = 10000\n",
    "EPOCHS = 10\n",
    "for i in range (2):\n",
    "    seq_len = 100\n",
    "    for j in range (2):\n",
    "        print('%d,%d' % (rnn_units, seq_len))\n",
    "        train_dataset, val_dataset = data_process(seq_len, text_as_int, BATCH_SIZE = 1, BUFFER_SIZE = 10000)\n",
    "        model = build_LSTM_model(vocab_size=len(vocab),embedding_dim=embedding_dim,rnn_units=rnn_units,batch_size=BATCH_SIZE)\n",
    "        checkpoint_dir = './training_checkpoints_' + str(i) + str(j)\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)\n",
    "        model.compile(optimizer='adam', loss=loss)\n",
    "        model.summary()\n",
    "        history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
    "        total_loss.append(history.history['loss'])\n",
    "        seq_len = int(seq_len/2)\n",
    "        model.evaluate(train_dataset)\n",
    "        model.evaluate(val_dataset)\n",
    "        print(generate_text(model, start_string=u\"JULIET\"))\n",
    "        print('-----------------------')\n",
    "    rnn_units = int(rnn_units/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.279541941002404,\n",
       " 2.1246030769446027,\n",
       " 2.087171628360514,\n",
       " 2.069256484664453,\n",
       " 2.0698333154455906,\n",
       " 2.0720343475347556,\n",
       " 2.0709186602128202,\n",
       " 2.0872065454427564,\n",
       " 2.091534156054648,\n",
       " 2.0921504330913363]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABEO0lEQVR4nO3deXxU1f3/8deZJfu+kg0SCCRhCfuOEEBEBVEUXGr3Wlvbau23m3bXfq10+1atWuuv2mptpQUXRJFFdgFBZN/DTliy7+ss5/fHnUwSSCBAJpNkPs/HI4+ZuXPnzpko8845957PUVprhBBC+C6TtxsghBDCuyQIhBDCx0kQCCGEj5MgEEIIHydBIIQQPk6CQAghfJzHgkAp9apSqkApta+N53+olNrl+tmnlHIopaI81R4hhBCtU56aR6CUmgxUAa9rrQdfYd/bgO9prad5pDFCCCHaZPHUgbXWG5RSqe3c/T7gzfbsGBMTo1NT23tYIYQQAJ999lmR1jq2tec8FgTtpZQKAm4GvtOe/VNTU9m+fbtnGyWEED2MUupUW891hZPFtwGbtNYlbe2glHpQKbVdKbW9sLCwE5smhBA9X1cIgnu5wrCQ1vplrfUorfWo2NhWezZCCCGukVeDQCkVDkwBlnizHUII4cs8do5AKfUmkAPEKKXygF8CVgCt9Uuu3eYCK7XW1Z5qhxCie7DZbOTl5VFXV+ftpnRrAQEBJCcnY7Va2/0aT141dF879vkH8A9PtUEI0X3k5eURGhpKamoqSilvN6db0lpTXFxMXl4eaWlp7X5dVzhHIIQQ1NXVER0dLSFwHZRSREdHX3WvSoJACNFlSAhcv2v5HfpMEBwrO8bvPv0dDY4GbzdFCCG6FJ8JgrPlp9mx7DU+Pb/N200RQnRRX/3qV4mLi2Pw4KaqOCUlJcyYMYP+/fszY8YMSktLAfjXv/5FdnY2Q4YMYcKECezevbvFsRwOB8OHD2f27NmtvteiRYsYNGgQJpPpkkmyTz/9NOnp6WRkZLBixQr39uXLl5ORkUF6ejoLFizoqI/tO0GQtTWfX77pZNfGt73dFCFEF/XlL3+Z5cuXt9i2YMECpk+fTm5uLtOnT3d/AaelpbF+/Xr27t3Lz3/+cx588MEWr3v22WfJyspq870GDx7M22+/zeTJk1tsP3DgAAsXLmT//v0sX76cb33rWzgcDhwOB9/+9rf58MMPOXDgAG+++SYHDhzokM/tM0EQdcssbFYT/ss24KlCe0KI7m3y5MlERbUsgrxkyRK+9KUvAfClL32Jd999F4AJEyYQGRkJwLhx48jLy3O/Ji8vjw8++IAHHnigzffKysoiIyPjku1Llizh3nvvxd/fn7S0NNLT09m2bRvbtm0jPT2dvn374ufnx7333suSJR0zBcvrtYY6izk0lJobhjH84x0cPrubzORh3m6SEKINTyzdz4FzFR16zIGJYfzytkFX/br8/HwSEhIA6NWrF/n5+Zfs88orr3DLLbe4Hz/66KP87ne/o7Ky8qrf7+zZs4wbN879ODk5mbNnzwKQkpLSYvvWrVuv+vit8ZkeAUCfz3+NoAY4tPhVbzdFCNENKaUuuSpn7dq1vPLKK/z2t78F4P333ycuLo6RI0d6o4nXxGd6BAC9xk/laKw/Qcs3w6Pebo0Qoi3X8pe7p8THx3P+/HkSEhI4f/48cXFx7uf27NnDAw88wIcffkh0dDQAmzZt4r333mPZsmXU1dVRUVHB5z//ed544412vV9SUhJnzpxxP87LyyMpKQmgze3Xy3d6BPZ61JEVVMwcQ8rJas7v+9TbLRJCdANz5szhtddeA+C1117j9ttvB+D06dPceeed/POf/2TAgAHu/Z9++mny8vI4efIkCxcuZNq0ae4QePzxx3nnnXeu+H4LFy6kvr6eEydOkJuby5gxYxg9ejS5ubmcOHGChoYGFi5cyJw5czrkM/pOEOxdBG/eQ/qNN2A3wbF//tXbLRJCdDH33Xcf48eP5/DhwyQnJ/PKK6/w2GOPsWrVKvr3789HH33EY489BsCTTz5JcXEx3/rWtxg2bBijRo264vH37t1Lr169AHjnnXdITk5my5YtzJo1i5kzZwIwaNAg7r77bgYOHMjNN9/MCy+8gNlsxmKx8PzzzzNz5kyysrK4++67GTSoY3pOHluq0lNGjRqlr2lhmrpy+MMA9LDPs/Dva8k4ZWfY5u2Y/Pw6vpFCiKt28ODBy15u2RPMnDmzxbwAT2ntd6mU+kxr3Wpa+U6PICAcMm5B7X+b6pvHEVhlo2Tl8iu/TgghOkhnhMC18J0gAMi+F2pLGDi4P4VhcPbf//B2i4QQwut8KwjSp0NQDKNO72DTcH/8dhykodkkECGE8EW+FQRmKwy+C78jK6i5cTROBWVvSckJIYRv860gABh6DzjqGR0Zye40RdHi/6AdDm+3SgghvMZngmBvXjnf+88uamOGQnR/bjizm7XDzKjCEqo//tjbzRNCCK/xmSAoq23gnZ1n2Xy8GIbeQ+SpT7CPzqQqxELZ4sXebp4QogvozDLUv/rVr0hKSmLYsGEMGzaMZcuWuZ9rqwy1p/hMEIxJiyLYz8zqQwUw5G4AbjAHsXqQg8o1a7EXFnq5hUIIb+vMMtQA3/ve99i1axe7du3i1ltvBdouQ+1JPhME/hYzkwfEsuZgATqiN/SZSM6ZvawZagKHgzJXaVkhhO/qzDLUbWmrDLUn+VTRuWmZcXy47wL7z1UwOPtu0pZ+F+vA0ZztV4V18WKiH3hA1kwVoiv48DG4sLdjj9lrCNxy9at6ebIM9fPPP8/rr7/OqFGj+OMf/0hkZORly1B7is/0CAByMuJQCtYcKoCBd6DM/kwhkKUDa7GdOk3Np1KITgjRto4sQ/3QQw9x7Ngxdu3aRUJCAt///vc91u4r8akeQWyoP0OTI1h9qIBHpveHjJvJObuFhzL8eXBNIGWLFxM8Zoy3mymEuIa/3D3FU2Wo4+Pj3fe//vWvu08qX64Mtaf4VI8AYHpmHLvPlFFYWQ/Z9zK8vAD/gECOjkmkcsVKHOXl3m6iEKIL8VQZ6vPnz7tf884777ivVGqrDLUn+VwQTMsy0nzt4QJIvxFrYBSTCGRRRgm6vp7ype97uYVCCG/pzDLUP/rRjxgyZAjZ2dmsXbuWP/3pT0DbZag9yXfKULtorZmwYA1DkyN46Qsj4YMfsOzQf/lxTDgL30ohUPmR9u47ctJYiE4mZag7jpShvgKlFNMy49iYW0i93QFD72VidQVmFIcmJlN/+DB1+/Z7u5lCiB5IylB3IdOz4qhucLDtRAkkjSQ8oi8jtB+L+1xABQTITGMhhE/xySCY0C+GAKuJ1QcLQCkYei85JRfYV38Cy/QbqHj/fZw1Nd5uphBCdAqfDIIAq5mJ/WJYfSgfrTVk301OTS0A+yYk4KyupmJ51+zCCSFER/PJIADj6qEzJbUcLaiCyFR6J44mzaH4IOQYfmlpMjwkhPAZvhsEmcZlpKsPFRgbsu8hp7Kc7fnbCZx7G7U7dlB/9KgXWyiEEJ3DZ4MgITyQgQlhrDnoCoJBd5BTb8OuHewfEwsWC2WL3/JuI4UQnS41NZUhQ4a0mBuwaNEiBg0ahMlkovnl66tWrWLkyJEMGTKEkSNHsmbNmlaP+fzzz5Oeno5SiqKiIvd2rTWPPPII6enpZGdns2PHDvdzr732Gv3796d///7uCW2e4rEgUEq9qpQqUErtu8w+OUqpXUqp/Uqp9Z5qS1umZ8Wx/VQJZTUNEBjJ0N7TiHBq1lZsJ3TaNMqXLMHZ0NDZzRJCeNnatWvZtWuX+0t/8ODBvP3220yePLnFfjExMSxdupS9e/fy2muv8YUvfKHV402cOJGPPvqIPn36tNj+4YcfkpubS25uLi+//DIPPfQQYKyB8MQTT7B161a2bdvGE0884V4HwRM82SP4B3BzW08qpSKAF4E5WutBwHwPtqVV07PicWpYf8RYi8A87D5uqK5hw5m1hN41F0dpKVVtJLwQwndkZWWRkZFxyfbhw4eTmJgIGDOCa2trqa+vb3W/1NTUS7YvWbKEL37xiyilGDduHGVlZZw/f54VK1YwY8YMoqKiiIyMZMaMGZesk9CRPFZ0Tmu9QSmVepldPge8rbU+7dq/wFNtaUt2UjgxIX58dLCA24clQfoMcpabWGqv4Wj/YMISEyhbtJiwm9vMMyGEB/x22285VHKoQ4+ZGZXJj8f8+Ir7KaW46aabUErxjW9845IFZ9ry1ltvMWLECPz9/dvdprNnz5KSkuJ+3Fhyuq3tnuLNcwQDgEil1Dql1GdKqS92dgNMJsXUjDjWHy7A5nCCxY8J/WZh0Zr1Zz4i4s67qN68mYY8z9YCF0J0HR9//DE7duzgww8/5IUXXmDDhg1XfM3+/fv58Y9/zF//+tdOaGHH82YZagswEpgOBAJblFKfaK2PXLyjUupB4EGA3r17d2gjpmfFseizPD47Vcq4vtGEDPs8oz/4gLUnlvPwnW9S9MILlL/9FrGPPNKh7yuEaFt7/nL3lMaSz3FxccydO5dt27Zdcm6guby8PObOncvrr79Ov379rvq9Wis5nZSUxLp161psz8nJuapjXw1v9gjygBVa62qtdRGwARja2o5a65e11qO01qNiY2M7tBGT+sdiNStjsRqA5FFMIZiT9SWcC7ERPGkSZW+9jfbwmqFCCO+rrq52rypWXV3NypUrWyxkf7GysjJmzZrFggULmDhxYovnvvjFL15xick5c+bw+uuvo7Xmk08+ITw8nISEBGbOnMnKlSspLS2ltLSUlStXMnPmzOv/gG3wZhAsASYppSxKqSBgLHCwsxsR4m9hXN9oVh90LT+nFDnpcwBYl7uEiHnzsOfnU/3xx53dNCFEJ8vPz2fSpEkMHTqUMWPGMGvWLG6++WbeeecdkpOT2bJlC7NmzXJ/KT///PMcPXqUJ598kmHDhjFs2DAKCow/Kvfs2eM+kfzcc8+RnJxMXl4e2dnZ7rWMb731Vvr27Ut6ejpf//rXefHFFwGIiori5z//OaNHj2b06NH84he/uGQt5Y7ksTLUSqk3gRwgBsgHfglYAbTWL7n2+SHwFcAJ/E1r/cyVjnu9Zahb8/dNJ3hi6QHW/SCH1JhgKDnOnW/dQkRYb16Z+wG5OVMJGjmC5D//uUPfVwjRpCeVoa6oqOBrX/saixYt8sr7d5ky1Frr+7TWCVprq9Y6WWv9itb6pcYQcO3ze631QK314PaEgKdMzzSWjHMPD0X1JccSyY7aC1Q4awm/4w4q167DXljorSYKIbqRsLAwr4XAtfDZmcXN9Y4Oon9cSFMQADl9Z+NQ8PH+fxExbx7Y7ZQvWeLFVgohhGdIELhMy4pj64liKutsAAwe9U2iHQ7W5y7Bv28agaNGUrZoMd1tRTchhLgSCQKX6Znx2ByajblGHRBTcAyTrTF8XHsWm62WiHnzaDh1ippPP/VyS4UQomNJELiM6B1BeKDVWKzGZUq/WVSaFDt2/52wmTMxhYRIeWohRI8jQeBiMZvIyYhl3eECHE5j+Gf8iG/gpzXrDr+NKTCQsNtmU7liJY7yci+3VgghOo4EQTPTMuMorm5gd14ZAEEBEYz1i2F97Tl0XQUR8+ah6+spf/997zZUCOExnihD/eUvf5m0tDT3XINdu3YBly9D3ZkkCJqZMiAWs0k1rVEA5KTdwhmrmeM7/07goEEEDBwoJ42F6OE6ugw1wO9//3t27drFrl27GDZsGNB2GerOJkHQTESQHyP7RDatWgZMHmLUwlt3xFikJmL+POoPHaJu/wGvtFEI0fmutwx1W9oqQ93ZvFl0rku6MSuO3yw7xLmyWhIjAukVkkCWNZL1lRf4WvlZwmbNIv+3v6Ns0SICBw/ydnOF6JEu/OY31B/s2DLU/lmZ9PrJT664n6fKUP/0pz/lySefZPr06SxYsAB/f/82y00nJCS070N1EOkRXGSaa5Zx815BTupN7Pb3o2TXa5jDwgibOZOK99/HWVPjrWYKITzEE2Won376aQ4dOsSnn35KSUkJv/3tbzu62ddFegQX6RcbTJ/oINYczOcL44xl5aZkzOUvuf9h46G3uH3y40TMn0f5kiVULF9BxJ1zvdxiIXqe9vzl7imeKEPd+Be+v78/X/nKV/jDH/7gfq/WylB3NukRXEQpxbTMODYdK6amwQ7AwKiBxFmCWe8ogwt7CBw5Er+0NJlTIEQP46ky1I3j/lpr3n33Xfcx2ypD3dkkCFoxPTOeBruTzUeLASMcpvSezqbAABp2/RulFBHz5lG7Ywf1x455ubVCiI7iqTLU999/P0OGDGHIkCEUFRXxs5/9DGi7DHVn81gZak/xRBnqizXYnQx/ciVzhiXx9J1DANiQt4Fvr/42fy1rYMJ39mMvKyd3Sg5RX/gC8T/+kUfbI4QvkDLUHafLlKHuzvwsJiYPiGXNoXz3fIExvcYQYLKy1lQPx9dhiY4mdNo0yt99F2dDg5dbLIToSqQMdQ8xLTOO/Ip69p+rACDAEsD4xAmsDwpG714IGHMKHKWlVLUxm1AIIboDCYI2TM2MQylarlHQexrnLSaOHF8O9VUET5iAJSGBskVy0liIjtDdhqq7omv5HUoQtCEmxJ9hKRFNaxkDk5ONS8jW+Sk4uBRlNhNx551Ub95MQ95ZbzVViB4hICCA4uJiCYProLWmuLiYgICAq3qdzCO4jOmZcfxh5REKKuuICw0gJjCGITGDWW/fxzf2LIRh9xFx51yKXnyR8rffJvaRh73dZCG6rcbF3QtlSdjrEhAQQHJy8lW9RoLgMqZlxvOHlUdYd6iQu0cb08BzUqby56J9FJ3aSEzFOaxJSQRPmkTZ228T8+1vocxmL7daiO7JarWSlpbm7Wb4JBkauoyshFASwgNYfahpeGhK8hQANgQGwF7jqoCIefOwX7hA9aZNXmmnEEJcDwmCy2icZbwxt4h6uwOAAZEDSAhOYG10Auz+DwChU3MwR0VR1o0uFxNCiEYSBFcwPSuOmgYHW4+XAEY45KTk8InZSV3hAbiwF+XnR/gdd1C5dh12Gd8UQnQzEgRXMKFfDAFWU8vLSJNzqNN2tgUFQeOcgnl3gd1O+ZIl3mqqEEJcEwmCKwiwmpmUHsPqZrOMR/UaRZAliLW90mHvYnA68O/bl8CRI2X1MiFEtyNB0A7TMuM5U1JLbkEVAH5mPyYmTWSD2Y6uugDH1wHGTOOGU6eo9XAtJCGE6EgSBO0wLTMOgNXN1zJOyaHAVsmBkEjYY5w0Dps5E1NIiJSnFkJ0KxIE7dArPIBBiWGsaXYZ6Q1JN2BSJtanDIGDS6G+ClNgIGG3zaZi+Qoc5eVebLEQQrSfBEE7Tc+M47NTpZRWG5VGIwMiGRo7lHUWB9hq4ND7gDGnQNfXU/7++95srhBCtJsEQTtNy4rHqWH9kabLQ6ckT+Fg1RkuRPZ2Xz0UOGgQ/gOz5KSxEKLbkCBop+ykcGJC/Fosaj81ZSoAG9JGwon1UGEsRxcxbx71hw5Rt/+AV9oqhBBXQ4KgnUwmxdSMONYfLsDmcAKQFp5GSmgK6yyAdrpLToTPno0KCKBsscw0FkJ0fRIEV2F6VjwVdXY+O1UKuNYyTp7C1uK91CSNcF89ZA4LI2zmTCre/wBnTY03myyEEFckQXAVJvWPwc9sarFGwdSUqTQ4G9iSNgby98GFfYAxp8BZVUXFipXeaq4QQrSLBMFVCPG3MLZvVIvzBMPjhxNqDWW9FTBZYI/rpPHIkfilpkohOiFEl+exIFBKvaqUKlBK7Wvj+RylVLlSapfr5xeeaktHmp4Zx/HCak4UVQNgNVmZlDSJ9Rc+wdnvRnfJCaUUEfPnUbtjB/XHjnm51UII0TZP9gj+Adx8hX02aq2HuX6e9GBbOsy0zHig5VrGU1KmUFJXwt70iVB53riCCAi//XawWChb/JZX2iqEEO3hsSDQWm8ASjx1fG/pHR1E/7iQFrOMJyVNwqzMrDfbwD8M9vwXAEtMDKHTplH+7rvohgZvNVkIIS7L2+cIxiuldiulPlRKDWprJ6XUg0qp7Uqp7V1hPdNpWXFsPV5CZZ0NgHD/cEbEj2DduU0w8HY48B40GENHEfPn4SgtpXLNWm82WQgh2uTNINgB9NFaDwX+DLzb1o5a65e11qO01qNiY2M7q31tmp4Zj92p2Zhb5N42JXkKuaW5nM2YAbZqOPQBAMETJmBJSJBCdEKILstrQaC1rtBaV7nuLwOsSqkYb7XnaozoHUFEkPWSaqQA65yVEJ7iLjmhzGYi7ryT6k2baMg7643mCiHEZXktCJRSvZRSynV/jKstxd5qz9WwmE3kDIhl7eECHE6jnlCfsD6khaexPm8DZN8Nx9dC5QUAIu6cC0D52297rc1CCNEWT14++iawBchQSuUppb6mlPqmUuqbrl3mAfuUUruB54B7dTeq0jYtK56S6gZ2nSlzb8tJzuHT/E+pyprjKjlhDAdZk5IInjiRsrffRjscXmqxEEK0zpNXDd2ntU7QWlu11sla61e01i9prV9yPf+81nqQ1nqo1nqc1nqzp9riCVP6x2I2qRZXD01JmYLdaWdTQz4kDndPLgOjEJ39wgWqN23yRnOFEKJN3r5qqNsKD7Iyqk9ki/MEQ2OHEuEfwfoz6yH7XriwF/KNCqSh06ZijoqibJGcNBZCdC0SBNdhelYchy5UcrasFgCLycINSTew8exG7APvAGV29wqUnx/hd9xB5dq12IuKLnNUIYToXBIE16GtWcZl9WXsrj0L6TfCnkXgNM4LRMy7C+x2yt991xvNFUKIVkkQXId+scH0iQ5iTbNqpBMTJ2IxWYzhoaH3QOU5OLkRAP++fQkcOZKSf/+b2j17vNVsIYRoQYLgOiilmJ4Zz6ZjxdQ02AEI8QthdPxo1uWtg4xbjZITu//jfk3sI4+ga+s4efc9nHnoW9QdPOil1gshhEGC4DpNz4qjwe5k09GmKRBTUqZwovwEp2oLYOAcOPgeNBgL1ASPHUO/VauIffS71Hz2GSfm3knedx+l/uhRb30EIYSPa1cQKKWClVIm1/0BSqk5SimrZ5vWPYxOjSLE39LiMlL3LOMz64yrhxqq3CUnAMwhwcR885ukf7SKmG89RPXGjRy/bQ5nf/gjGk6e7NT2CyFEe3sEG4AApVQSsBL4AkaZaZ/nZzExeUAMqw8W0DgfLikkifSIdNbnrYc+E42SE83mFDQyh4UR+8gj9Fv9EdFf+yqVq1ZxbNZszv30p1KOQgjRadobBEprXQPcCbyotZ4PtFkt1NdMy4ynoLKe/ecq3NumpkxlR/4Oym2VMGQ+HFsDlfmtvt4SGUncD35A+qqVRN7/OSqWvs+xW27h/BNPYMtv/TVCCNFR2h0ESqnxwP1A4xiH2TNN6n5yMmJRihaTy6akTMGhHWw6uwmG3muUnNh3+clklthYev3kJ/RbuYKIu+6kbNFijs24ifynn5a5B0IIj2lvEDwKPA68o7Xer5TqC0iBfZeYEH+GpUS0OE8wJGYIUQFRxnmC2AxIGOauSHol1l69SPjVr+i3/EPCZs+m5I1/cXTGTRT88Y/YS0s98hmEEL6rXUGgtV6vtZ6jtf6t66Rxkdb6EQ+3rVuZnhnH7rxyCirrADApE1OSp/Dx2Y+xOW1Gr+DCHiho/+WifsnJJP7mKfq+v5TQ6dMp/tsrHLtxBoXPPYejouLKBxBCiHZo71VD/1ZKhSmlgoF9wAGl1A8927TuZXqWMct47UWzjCttlezM3wmD7zJKTrSzV9Ccf1oaSX/4PX3fW0LwxIkUvfgXjt44g6KXXsJRVd1hn0EI4ZvaOzQ0UGtdAdwBfAikYVw5JFwye4WSGB7Q4jzB+ITx+Jn8WHtmLYTEQb9psHcROJ3X9B7+/fuT/NyzpL39FkEjRlD4zLMcmzGD4ldexVlb21EfRQjhY9obBFbXvIE7gPe01jag26wd0BmUUkzLiuPjo0XU2YzaQkHWIMYkjGF93nrj0tKh90LFWXfJiWsVMHAgKS/9hdT/LCQgK4uC3/+eozfdRMk/38DZ0NARH0cI4UPaGwR/BU4CwcAGpVQfQAapLzI9M56aBgdbT5S4t01NmcqZyjOcKD9hlJzwC4U9/7nMUdovcOhQer/6Cn3e+Cf+fVLJf+opjs28mdL//hdts3XIewgher72nix+TmudpLW+VRtOAVM93LZuZ3y/aAKsphZF6CYnTwYwag/5BcHA243hoTX/C/VVHfK+QaNG0fufr9P71VewxMVy4Re/5Nitsyh751203d4h7yGE6Lnae7I4XCn1f0qp7a6fP2L0DkQzAVYzk9JjWH2oaZZxr+BeZEVlGZeRAtz4K8icDRt+D88Nh8/+4S5TfT2UUgRPmEDqwoUkv/QXTKEhnH/8cY7fNofyDz5AX+N5CSFEz9feoaFXgUrgbtdPBfB3TzWqO5uWGU9eaS25BU1/7U9JmcLuwt2U1pVCSCzM/zt87SOISoOl34WXJsHRjzrk/ZVShObkkPbWWyQ99yzKYubc93/AiTvmUrFqlTughBCiUXuDoJ/W+pda6+OunyeAvp5sWHc1LTMOaDnLOCclB6d2svFss5PEKaPhqytg/mtgq4E37oJ/3gn5+zukHUopwm66ibR33yXxD39ANzRw9uFHODlvPlXr10sgCCHc2hsEtUqpSY0PlFITAblesRW9wgMYnBTG6mbnCQZGDSQuMK5peKiRUjDoDvj2NrjpKTi73egdvPdwm3WJrpYymwmfPYu+7y8l4Te/wVFWxplvfJNT932OipUrcZSXd8j7CCG6L0s79/sm8LpSKtz1uBT4kmea1P1Ny4zn+TW5lFQ3EBXsh1KKySmTWXZ8GQ2OBvzMfi1fYPGHCd+BYZ+D9b+DT/8f7H0LJj0K479jnGS+TspiIeLOuYTPnkXZ2+9Q9NJLnH3ku6AUAVlZBI0dS9DYMQSNGoU5JOS6308I0X2096qh3VrroUA2kK21Hg5M82jLurHpmXE4Naw/0jQ8NDVlKjX2GrZf2N72C4Oi4JYFRg8hfRqsfQr+PAJ2/fuaJ6FdTPn5EXnvPaSvXEGff75OzLe/jSk4mNI33iDvmw9xZOw4Ttx9DwV//CNVGzfirJaZy0L0dOpax4qVUqe11r07uD1XNGrUKL19+2W+TLsAp1Mz5jerGdc3iuc/NwKAOnsdNyy8gbn95/KTsT9p34FObYYVP4VzO6DXEGP4qO8Uz7S5ro7aXbuo3rqVmq3bqN27F2w2sFgIHDyYoLFjCR47hsDhwzEFBnqkDUIIz1FKfaa1HtXqc9cRBGe01inX1bJr0B2CAOBHi3fz4b4L7Pj5DKxmo+P18JqHOVxymBV3rUAp1b4DOZ2w7y1Y/QSUn4EBN8OMX0PsAA+2Hpw1NdTs3EnN1m3UbN1K7b594HCgrFYChmYTPGYsQWPHEjhsKCZ/f4+2RQhx/S4XBO09R9AauezkMqZlxvPf7XlsP1nK+H7RAOQk57DuzDqOlB4hIyqjfQcymSB7PmTdBlv/Ahv/D14cB6O+AjmPQ3CMR9pvCgoiZOJEQiZOBMBRVU3tjs/cPYail16CF19E+fsTOGwYQWPHEDx2LIFDhqD8/K5wdCFEV3LZHoFSqpLWv/AVEKi1vp4guSbdpUdQVW9nxJOr+NKEPvx01kAAimqLmPrfqTw8/GEezH7w2g5cXQTrnobtfwdrENzwPzDuW2AN6MDWX5mjooKa7Z9Rs3Ur1du2UX/oEGiNCgwkaPhw91BSwODBKEun/28ihLiIR4aGvKW7BAHAF17ZytmyWtZ8P8e97XMffA6HdvDmrDcxqfZevduKwsOw6pdw5ENjTeTpvzRKXZuu45jXwVFWRvWnn7qHkupzcwGjZxE4aiTBY8cSNGYsAQOzUGZZ3E6IziZB4CWvbT7JL9/bz9of5JAWY1Tk+NfBf7Fg2wLG9BrDU5Oeoldwr+t7k+PrYeXPjEVvEkfAzKegz4QOaP31sZeUULNtm3soqeH4cQBMoaEEjRrlHkryz8hAeSm8hPAlEgRecqakhht+t5afzcrigRuMidhaa945+g4Lti3AYrLwi/G/4ObUm6/vjZxO2LMQVv8aKs8ZtYxmPAnR/TrgU3QMW0EBNds+pWab0WNoOHUKAFN4OIHZ2QRkZuA/IIOAzAz8UlNRVquXWyxEzyJB4EU3/Wk9MSH+/Pvr41psP11xmsc3Ps6eoj3c1vc2fjL2J4T4XedEroYa2PICfPwncNTD6K/DlB8Z8xO6GNuFC+4eQ92BgzQcPeouna2sVvz6pxMwIAP/zAwCMjLwz8zEEhnp5VYL0X1JEHjRgg8P8beNx9nxixmEBbT8K9fmtPHynpd5ec/LJAQn8PQNTzM8bvj1v2llvjEZbec/wT8UJv8IxnzdmMHcRWmbjfrjJ6g/cpi6Q4eoP3yEusOHcBQWufexxMbin5kpvQchroEEgRd9erKE+S9t4YXPjWBWdkKr++wq2MXjGx/nXPU5HhjyAN8c+k2spg74css/AKt+blQ2jUw1SmAPvMOocdRN2IuLqT98mLrDR6g/dIi6w4epP3bMmOyG9B6EaC8JAi+yO5yMeuojpmXG8X93D2tzv2pbNQu2LeDdo+8yOHowT9/wNKnhqR3TiKOrYeXPoWA/pIw1ZiinjO6YY3vBVfUeMgbgn5EpvQfh87wSBEqpV4HZQIHWevBl9hsNbAHu1VovvtJxu1sQADy6cCcbcov49Kc3YjZd/q/xlSdX8sSWJ7A5bfxw9A+Z139e+2chX47TATvfMIaMqvJh0J0w9ScQ0//6j91FuHsPhw67ehHSexCikbeCYDJQBbzeVhAopczAKqAOeLWnBsHS3ed4+M2dvPXQBEb2ufKXTn51Pj/d9FO2nt/K1JSp/GrCr4gK6KATvvVVsOlZ2PxnsNdCbBZk3mqsp5w4wmvzEDyl3b2HjAysiYlYYmOxxMZgiTF+zDGxWGKiMQV07oQ9ITqa14aGlFKpwPuXCYJHARsw2rVfjwyC8lobI369im9M7suPbs5s12uc2skbB97gmR3PEO4fzq8n/ppJSZOu/ML2qrwA+96Gw8uM4nbaASG9IONmyJgFaZM7fbZyZ7qk95B7BPuFfBylpdDKvwlTaKgRDrGxrtsYzDExWGKaHltiYjBHRsqEOdEldckgUEolAf8GpmIshdljgwDg3pe3UFZjY/mjk6/qdYdLDvPYxsc4WnaU+zLv439G/g8Blg7+gq4pgdxVcPgD43xCQxVYg41S2BmzYMDMLnkJqidomw17SSn2okIcRUXYi4qwF7pui4qM7YVF2AsLcdbUXHoAkwlzdFRTYDQGRfOwcAWKKTi4Y4b9hGgHTxWdu17PAD/WWjuv9I9BKfUg8CBA796dXvm6Q0zPjOepZQfJK60hObL9C81kRGWwcPZCnvnsGd44+AZbz2/lt5N/S2ZU+3oW7RIUBUPvMX7s9XBig9FTOPwhHFwKygy9x7uGkG6BqJ67SqmyWrHGx2GNj7vivs7qauzFxc3CohB7UZERIK7wqD98BHtxMdjtl75XYGBTSDT2MqKiMYUEYwoMwhQUiCkwEBUY2PQ4KMi1LQhTYID0PkSH8GaP4ARG8TqAGKAGeFBr/e7ljtldewTHCquY/sf1/Pr2QXxhfOo1HWPz2c38bNPPKK0v5ZHhj/ClQV+6vnpFV+J0wvmdcMgVCgWu9ZTd5xVmQeLwHndeoaNppxNHeTn2wsv0MoqKsBcUXvXSocrfH1OgERAqyBUYga4AcQeHa1tQW6HSdN99rMBAKf3Rw3TJoaGL9vsHPXxoSGvN1D+sIzUmmH98Zcw1H6e0rpQntjzB6tOrGd1rNL+Z9Jvrr1fUXiUnjEDw0fMKnUHbbDhra42fmhq0+77x2Fnr2lbj2l5bY+znfmxs0+79m7Y3Xj3VbiYTymIxqsdarcb9xluLBWW1gKXZ48ZtVivqou1YG+9bm45htUDjthbHbHyfpv0aX0PzYzQe0/2ctcW+7v1l+A3w3lVDbwI5GH/t5wO/BKwAWuuXLtr3H/TwIAB4cukB3th6il2/mEGQ37WPymmteffouzy97WmjXtG4X3Bz2nXWK7paNSWQu9IIhRbnFaZD5izof5PPnFfoLtwhU1PjCpLLBE1tHdpuA7sdbbOj7Y0/NqMUSCvbafG42Tab7aLtdnBta+3EfIdrLcRcj42Asl4acC2CyIoyd43eUciUKYTdeus1vVYmlHURm44Wcf/ftvL/vjiKGQPjr/t4ZyrO8NjHj7Gn0KhX9PjYxwn1C+2All4lWx2c3AiHPjB6DFUXLjqvcCtEpXV+u0SXpx0OIxxsdnCFjDswbPamMLK7AqUxbGwNRpBcst3WLMAu3t4syFrZjt2Obmj+/jb3bUetGX69Iu+9h+gHHrim10oQdBENdicjf72K2UMTePrO7A45pt1p5+U9L/PXPX+lV1Avnr7haUbEj+iQY1+TFucVlkHBAWN73EAjEDJulfMKQniBBEEX8u1/7WDL8WL++43xpMddZ7XRZprXK/ra4K/x0LCHOqZe0fUqOdF0BVLjeYXQBGPt5UzXeYUuXAxPiJ5CgqAL2X2mjC//fRv1die/mTuEO4Ynddixm9crGhQ9iAU3LOi4ekUdofG8wiHXfAVbNfiFQMoY6JUNCdnQa6hxear0GIToUBIEXcz58loeeXMnn54s5Z5RKfxqziAC/TruevBVp1bxxJYnaHA0dGy9oo7UeF7h8DLI+xQKDoHTdVWLXwjED3YFgysgYrPA4ufdNgvRjUkQdEF2h5P/W3WEF9cdIyM+lBfuH9GhQ0X51fn8bNPP+OT8J+Sk5PDEhCc6rl6RJ9gboPAgnN9jLLt5fg/k7zOuRgIwWSEu0+gxNAZEr8HGegtCiCuSIOjC1h0u4H/+u5s6m4On5g5m7vDkDjt283pFYX5hPDnxSSYnX12JC69yOqHkOFzY3TIgahoLxiljGKl5z6HXUAiJ9WqzheiKJAi6uAvldTzy5k62nSzxyFDRkdIj/HjDjzladpR7M+7l+6O+3/H1ijqL1lB5vlkw7DZuy0437ROa0CwYXLcRfbrVgjxCdDQJgm7A7nDyzEe5vLDuKAPiQnnh/uGkx3XcsEe9o55ndzzLPw/8k77hfVlwwwKyorM67PheV1sKF/a27DkUHQbtuv47INw1nNQsIGIGgNmb5baE6DwSBN3I+iOFfO8/u6htcPC/dwzmrpEdN1QEsPncZn7+8c8pqS/hq4O/yj0Z9xAXdOUCa92SrdZYrrP50FL+frDXGc9bAoz5DY3BEJUGYUlGjyIgzLttF6KDSRB0MxfK63hk4U62nSjh7lHJPDFncIcOFZXVlfHU1qdYfnI5ZmVmSvIU5mfMZ0LiBM8WsesKHHYozr10aKnuomJvfqEQltjKT5JxG5polNCQ4SbRTUgQdEN2h5NnV+fy/Nqj9I8L4YXPjaB/fMdeIXO64jSLcxez5OgSSupKSApJ4q7+dzG3/1xiAmM69L26NK2hPA/Kz0DFOag467pt9lN1oWmYqZHZv1k4JLQMisawCIkDk5SKFt4nQdCNbXANFdV4aKgIoMHRwJrTa1h0ZBHbLmzDoixM7T2VeQPmMS5hXM/vJbSHw26s9Vx5vllQNN66tlWeB0dDy9cpszHUFJboCouLgiIs0Xhe5kgID5Mg6ObyK4yriraeKGHeyGSevH3QdVUvvZyT5SdZfGQxS44toay+jJTQFO7qfxd3pN9BdGC0R96zx3A6oaYYKs+13bOoOAu2VlY2C45rCoWgKAiMhMAICIhouh8Y2fQ4IFx6GuKqSBD0AHaHk+dW5/LntUdJjw3hxfs7fqiouXpHPR+d+ohFRxbxWf5nWEwWbux9I/MHzGd0r9Fdb6Zyd6G1cT6i4lyzwGgMjfNGr6K21PhpLTCaCwhvOygu99gvWM5tdAdOh/H/QEONUY7FVmv8NwxLvKbDSRD0IBtzC3l0oTFU9Os7BjPPA0NFFztedpxFRxbx3rH3qGioIDUslXkD5jGn3xwiAyI9/v4+y14PtWVQV+YKB9et+3Fr21y32tH2cU3WpmBoKywCwsEvCCyBYA0Ea5Dr9qL75i5Q2NBbnA5ocH1B26pdX9jN79c0+yJv/Kl1vaaV5y6+76i/9D0nfQ9u/NU1NVeCoIfJr6jjuwt38slxzw8VNVdnr2PVqVUsOrKInQU7sZqs3NjH6CWMih8lvYSuQmujNMflgqLVx2VQX3F172WytB4S7gBpHhyNtwGtbGvjdSaLUYPKYTPOvzjtxq3D1vK+w9ZsP9t1vqbxfoNxbshpc33B17q+pF1f/q19UV+WMj6TX5Dr817D/dhMo9TKNZAg6IEcTs2zq3P585pc0mNDeOH+EQzw4FDRxXJLc1l8ZDFLjy2l0lZJWnga8wfMZ06/OYT7h3daO0QHc9iNoau6MmO+ReOX3yW3bTxnr235pXnJ/tWXXn3V2ZTZ6MmY/YygMfsZjy933x1Owa4vZtd9a6DrceP94KZQc993fZlbArw6JCdB0IN9nFvEo//ZSVW9nV/fPpj5o1I69f1r7bWsOLmCRUcWsadwD34mP2amzmR+xnyGxQ6TXoJoSWvjL+52BUeN8Rd88y9ls9UY2mpx/wpf5M1fY7L6bIlzCYIerqCiju8u3MWW48XcOSKJ/71jcKcMFV3scMlhFh1ZxPvH36faVk16RDrzBszjtn63EeYnM3WF8CYJAh/gcGqeW53Lc2ty6RdrTEDL6OWdEs01thqWn1zOosOL2Fe8jwBzgLuXkB2TLb0EIbxAgsCHbDpaxHcX7qKq3saTtw9m/shkr37xHig+wKIji1h2fBk19hoGRA5g/oD5zOo7i1A/WUtAiM4iQeBjCirreHThLjYfK+bO4Un8+o7BBPt7t8pmta2aZSeWsejwIg6WHCTQEsgtabcwf8B8BkUPkl6CEB4mQeCDHE7Nn9fk8uzqXPrGBPPi/SO9NlR0sf1F+41ewoll1Npr6R3amwmJE5iQOIHRvUYT4tdxK7UJIQwSBD5s89EiHnENFT0xZxB3j0rpMn99VzVUsezEMjbkbWDbhW3U2muxKAvZsdnuYBgYPRCzlFIQ4rpJEPi4gso6vvefXWw6Wszc4cZVRd4eKrqYzWFjV+EuNp/bzOZzmzlYfBCNJswvjHEJ45iQOIHxieNJDLm26fVC+DoJAoHDqXlh7VGe+egIaTHBvHD/CDJ7dd1LOkvqSth6fqs7GApqCgBIDUt19xZG9RpFsDXYyy0VonuQIBBum48ZVxVV1Np47JZM7h/bBz9L155go7XmePlxdyhsv7CdOkcdFmVhaNxQJiZOZELiBDKjMmUYSYg2SBCIFgor6/mf/+5iY24RSRGBfHtqOvNGJnf5QGjU4GhgZ8FONp/bzJZzWzhYchCACP+IFsNIvYJ7ebmlQnQdEgTiElprNuQW8adVR9h1pqxbBkKj4tpiPjn/iTsYCmsLAegb3tcdCqPiRxFkDfJyS4XwHgkC0aaeFAhgfJ6jZUfdobA9fzv1jnosJgsj4kYwPnE84xPHkxWVJSuvCZ8iQSCuSGvN+iOFPPNRrjsQvjMtnbtGdM9AaFTvqGdH/g62nNvC5nObOVx6GIBI/0jGJYxjfOJ4JiROID443sstFcKzJAhEuzUGwp8+ymV3DwqERkW1RWw5t8UdDMV1xQD0C+9Hdmw2mVGZDIweyIDIATKUJHoUCQJx1bTWrHP1EHafKSM5MpDvTE3nzh4SCGB8xiOlR9hybgufnP+E/cX7KasvA0Ch6BPWh6yoLDKjM8mMyiQrKktWZBPdlgSBuGbuQFh1hN155e5AuGtkMlZzzwiERlpr8mvyOVh8kEMlhzhYYtyerz7v3ic+KP6ScEgITugys7WFaItXgkAp9SowGyjQWg9u5fnbgV8DTsAOPKq1/vhKx5Ug8A6tNesOF/LMRz0/EC5WVlfGodJDHCpuCoeTFSdxulbaCvcPJzPSCIbMaCMcUsNSZU6D6FK8FQSTgSrg9TaCIASo1lprpVQ28F+t9RUX45Qg8K7GQPjTR0fY4wqEh6cZQ0Y9PRCaq7HVkFuW2yIccktzaXA2ABBgDmBA5IAW4dA/sj/+Zn8vt1z4Kq8NDSmlUoH3WwuCi/YbD7yqtc660jElCLoGrTVrDxfwzEe5Ph0IzdmcNk6UnzCGlVzDS4dLDlNpqwTArMz0jehrDC1FZbp/ZF0G0Rm6bBAopeYCTwNxwCyt9ZYrHVOCoGu5OBBSogJ5eGp/5o5I8tlAaE5rTV5VXotwOFRyyD3pDSA5JJms6KZw6B3am8SQRPzMfl5suehpumwQNNtvMvALrfWNbTz/IPAgQO/evUeeOnWqo5sqrpMEwtUpqi1yh0JjQJyuPO1+XqGID44nOSSZlNAUkkOTSQ5JNm5Dk4n0j5QT1OKqdPkgcO17HBijtS663H7SI+jatNasOWQEwt6zEghXo6qhityyXPIq8zhTeYa8yjzyqvLIq8xr0YMACLIEXRIOKaEpJIckS29CtKpLBoFSKh045jpZPAJYCiTrKzRIgqB7uDgQekcF8Z1p6cwdLoFwLWrttZyrOtciHNyBUZVHvaPevW/z3sTFYZEckkxUQJT0JnyQt64aehPIAWKAfOCXgBVAa/2SUurHwBcBG1AL/FAuH+15tNasPljAM6uPsO9shQSCB2itKaotahEQze8X1Ba02L+13kTj/aSQJOlN9FAyoUx4nQSC99TZ64zeRFWzIadmYVHnqHPvq1DEBcWRFJJEfHA88UHxxAXFERcUR3yQ8TgmKAaryerFTySuhQSB6DK01nx0sIBnPjrC/nMV9IkO4kvjU5mdnUBcWIC3m+dztNYU1xW3GGbKq8zjbNVZCmoKKKgpaDHsBEZYRAVENYVDcFNYNA+MEL8QL30q0RoJAtHlNAbCn9cYVxkpBePSorltaCI3D+5FVLAMT3QFWmvK68vJr8l3B0NBTQH5NfkttjXWaGouyBLkDgZ3SLhCo3FbdEC0zMDuJBIEokvLza9k6Z7zvL/7HMeLqjGbFJPSY7htaCI3DYonLECGIbq6OnsdhTWFLcKh8X7jbWFNIXZtb/E6szITExjTIiwaf3oF9yImMIaogCjC/MLkBPd1kiAQ3YLWmv3nKnh/z3mW7j7H2bJa/MwmpmTEctvQRG7MiiPIz+LtZopr5NROSupKjHCobhkSze9X2aouea1FWYgIiCAyIJKogCii/KPc993bmt0P9QuVhYcuIkEguh2tNTvPlLF09zk+2HOegsp6Aq1mpmfFMTs7kZyMWAKsMqTQE9XYapp6EbWFlNaVUlJX0uptY/mOi5mVmciASCMY/JtC4uLQiAyIJDog2ieCQ4JAdGsOp+bTkyUs3X2OD/ddoKS6gVB/CzMGxXPb0EQmpcfIlUc+qsHRQGldKaX1Rjg0BkRjWFxNcET4RxAV2HpvI8w/jFBrKCF+Ie7bEGsIgZbAbjNkJUEgegy7w8nmY8Us3X2O5fsvUFlnJyLIyi2De3FbdiJj+0ZjNnWPf5ii89kctktCo/mtO0jqSympLWkzOBqZlZlgazChfqGEWEOa7ruConF7iDXECJHGx35N24ItwZ1ywlyCQPRI9XYHG48UsXTPOVYdyKemwUFsqD+zhiQwOzuBEb0jMUkoiOvQGBzl9eVU26qpbKikylblvq1qqHLfVtoqWzxuvL34BHlrgq3BLQKjec8j1BpqPO8XwpCYIWTHZl/TZ5EgED1ebYODNYcKWLr7HGsOF9Bgd5IYHsDsoYnclp3I4CS56kR0Pq01dY66KwZGa8HSfHvjXI4HhjzAd0d895raIkEgfEplnY2PDuazdPd5NhwpxO7UpEYHMTs7kduGJpLRS+r/i+7F5rBRZavCbDIT5hd2TceQIBA+q6ymgRX7L7B093k2HyvCqWFAfAi3ZScye2giaTHB3m6iEJ1CgkAIoLCyng/3nef93efZdrIEgMFJYdyWncis7ASSI4O83EIhPEeCQIiLnCurZdleY+La7rxyAPrGBDO8dyQj+kQwPCWSjF6hcgWS6DEkCIS4jFPF1Xy47wLbT5aw43QZJdXGAvRBfmaGJke4g2F47wiiQ2TxedE9SRAI0U5aa06X1LDzdBk7Tpey43QpB89X4nAa/076RAcxorcRCiN6R5LZKxSLTGYT3cDlgkAKtwjRjFKKPtHB9IkO5o7hSYBxaeqevDJ2niljx6lSNuYW8c7OswAEWs0MSQ5vEQ6xodJrEN2LBIEQVxDoZ2Zs32jG9o0GjF5DXmmtOxh2ninjlY+PY3MYvYbkyMAWwZCVEIafRXoNouuSIBDiKimlSIkKIiUqiDlDEwGosznYf66cHafK2HmmlG0nSnhv9zkA/C0mhiSFu4NheO9IeoXLIjyi65BzBEJ4yPnyWiMYXOca9p2toMHhBCAxPIDhjb2GPpEMSgzD3yLVVIXnyDkCIbwgITyQWdmBzMpOAIzaSAfOVbhPRO88XcYHe88D4Gc2MSgpjGEpEaTHhZAaHUxqTDAJYQFSL0l4nASBEJ3E32J29QIi+SppAORX1LHztNFr2Hm6jDe3nabO5mz2GhN9ooNIjQ4mLcY4iZ0aE0RaTDDxoRISomNIEAjhRfFhAdw8uBc3D+4FgNOpuVBRx8miak4UVxu3RTWcKKpm3ZFCGuxNIRFgNZEaHWwERUwwaa5eRFpMMHGh/lJkT7SbBIEQXYjJpEiMCCQxIpAJ6TEtnnM4NefLazlZVOMOiVPF1RwtqGLNoQL3VUtgXNbaJ9roOTQPidToIGIlJMRFJAiE6CbMJkVyZBDJkUFM6n9pSJwrq+WEKxxOFNVwsriawxcqWXUgH7uzKSSC/cz0cQ01pcYENd2PDiYmxE9CwgdJEAjRA5hNTZe0QmyL5+wOJ2fLajlZXOMaaqrmZHE1+8+Vs3z/BfesaYAQfwupMUGkRAYRFexHZJAfEUFWIoL8iGx2GxnkR1igVWox9RASBEL0cBazyT1besqAliFhczg5W1rrHmo6WVTNyeIaDudXUlZjo6ymAWcbV5grBeGBVndYNL+NDLIS3iw0mrb7Eegnl8leLYdTU2dzYFLKI78/CQIhfJjVbDLOHcQEQ8alzzudmso6O6U1DZTV2ozbmgZKq42QKK1p3GYjv6KOwxcqKa1poKbB0eZ7+ltMLcMhuFmPI7Dl9hB/K2aTMYnPrBQmpTCZjB6QqfGxMh4rpTCbjP2Uar4PHT7cpbWm3u6kzuag1uagzmbcb3xc3/jYbjxX29B0v979mqbXuV9jb9reuE+9zemef/KtnH786ObMDv0sIEEghLgMk0kRHmQlPMh6Va+rtztcPYpm4dEsNEqrjcdlNQ0cvuDqfdTaWgxTdSSlMILE5AoOd6g0BUljsBih0jJIjL/IjS/q2gYH9c2u3rpa/hYTAVYzgVYzAVbjvr/VTKDVRFSwHwGWpu1NP8bjEb0jO/C30kSCQAjR4fwtZuLDzMSHtb+Uhtaaijo7ZY1hUdNAdb0Dp9buH4fT6KU4tcahNU7d7LGzcT/ji1s37q+bP+967DRer137Gveb7eN+D+O+2aTcX8aBri/uAKuJAIuZQL+m+8aXusn1Jd/0Jd742M9s6pJzPyQIhBBdglKK8EAr4YFW+kR7uzW+RUoiCiGEj5MgEEIIHydBIIQQPk6CQAghfJwEgRBC+DgJAiGE8HESBEII4eMkCIQQwsd1uzWLlVKFwKlrfHkMUNSBzenu5PfRkvw+msjvoqWe8Pvoo7WObe2JbhcE10Mptb2txZt9kfw+WpLfRxP5XbTU038fMjQkhBA+ToJACCF8nK8FwcvebkAXI7+PluT30UR+Fy316N+HT50jEEIIcSlf6xEIIYS4iM8EgVLqZqXUYaXUUaXUY95ujzcppVKUUmuVUgeUUvuVUt/1dpu8TSllVkrtVEq97+22eJtSKkIptVgpdUgpdVApNd7bbfIWpdT3XP9G9iml3lRKtX+lnW7EJ4JAKWUGXgBuAQYC9ymlBnq3VV5lB76vtR4IjAO+7eO/D4DvAge93Ygu4llgudY6ExiKj/5elFJJwCPAKK31YMAM3OvdVnmGTwQBMAY4qrU+rrVuABYCt3u5TV6jtT6vtd7hul+J8Q89ybut8h6lVDIwC/ibt9vibUqpcGAy8AqA1rpBa13m1UZ5lwUIVEpZgCDgnJfb4xG+EgRJwJlmj/Pw4S++5pRSqcBwYKuXm+JNzwA/Aq59RfKeIw0oBP7uGir7m1Iq2NuN8gat9VngD8Bp4DxQrrVe6d1WeYavBIFohVIqBHgLeFRrXeHt9niDUmo2UKC1/szbbekiLMAI4C9a6+FANeCT59SUUpEYIwdpQCIQrJT6vHdb5Rm+EgRngZRmj5Nd23yWUsqKEQL/0lq/7e32eNFEYI5S6iTGkOE0pdQb3m2SV+UBeVrrxh7iYoxg8EU3Aie01oVaaxvwNjDBy23yCF8Jgk+B/kqpNKWUH8YJn/e83CavUUopjDHgg1rr//N2e7xJa/241jpZa52K8f/FGq11j/yrrz201heAM0qpDNem6cABLzbJm04D45RSQa5/M9PpoSfOLd5uQGfQWtuVUt8BVmCc+X9Va73fy83yponAF4C9Sqldrm0/0Vov816TRBfyMPAv1x9Nx4GveLk9XqG13qqUWgzswLjSbic9dIaxzCwWQggf5ytDQ0IIIdogQSCEED5OgkAIIXycBIEQQvg4CQIhhPBxEgTCZymlqly3qUqpz3XwsX9y0ePNHXl8ITqSBIEQkApcVRC4ipBdTosg0Fr3yBmpomeQIBACFgA3KKV2uerPm5VSv1dKfaqU2qOU+gaAUipHKbVRKfUertm2Sql3lVKfuWrWP+jatgCjYuUupdS/XNsaex/Kdex9Sqm9Sql7mh17XbN1AP7lms0qhMf5xMxiIa7gMeAHWuvZAK4v9HKt9WillD+wSSnVWHVyBDBYa33C9firWusSpVQg8KlS6i2t9WNKqe9orYe18l53AsMw6vzHuF6zwfXccGAQRqnjTRgzwD/u6A8rxMWkRyDEpW4Cvugqv7EViAb6u57b1iwEAB5RSu0GPsEobNify5sEvKm1dmit84H1wOhmx87TWjuBXRhDVkJ4nPQIhLiUAh7WWq9osVGpHIyyzM0f3wiM11rXKKXWAdezlGF9s/sO5N+n6CTSIxACKoHQZo9XAA+5SnWjlBrQxuIs4UCpKwQyMZb9bGRrfP1FNgL3uM5DxGKsBratQz6FENdI/uIQAvYADtcQzz8w1uxNBXa4TtgWAne08rrlwDeVUgeBwxjDQ41eBvYopXZore9vtv0dYDywG9DAj7TWF1xBIoRXSPVRIYTwcTI0JIQQPk6CQAghfJwEgRBC+DgJAiGE8HESBEII4eMkCIQQwsdJEAghhI+TIBBCCB/3/wG8k/u5gOyrnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = range(len(total_loss[0]))\n",
    "plt.plot(t, total_loss[0], label='1024,100')\n",
    "plt.plot(t, total_loss[1], label='1024,50')\n",
    "plt.plot(t, total_loss[2], label='512,100')\n",
    "plt.plot(t, total_loss[3], label='512,50')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = total_loss[0]\n",
    "draw_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.append(loss)\n",
    "#(1024,100), (512,100), (256,100), (1024,50), (512,50), (256,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "    1/19683 [..............................] - ETA: 22:08"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'loss_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-263-494827c22808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#model.compile(optimizer='adam', loss=loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 497\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[1;34m(input_iterator)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_feed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[1;32m---> 85\u001b[1;33m         per_replica_function, args=args)\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[0;32m    762\u001b[0m                                 convert_by_default=False)\n\u001b[1;32m--> 763\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1817\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1819\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2163\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[1;32m-> 2164\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2166\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(model, x, y, sample_weight, reset_metrics, standalone)\u001b[0m\n\u001b[0;32m    503\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    356\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     loss_fns = [\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mloss_fn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     ]\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_fns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'loss_functions'"
     ]
    }
   ],
   "source": [
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-54e9e713d564>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    913\u001b[0m     \"\"\"\n\u001b[0;32m    914\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2829\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (1, None, 512)            393728    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (1, None, 65)             33345     \n",
      "=================================================================\n",
      "Total params: 443,713\n",
      "Trainable params: 443,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#print(tf.train.latest_checkpoint('./RNN_checkpoints'))\n",
    "rnn_units = 512\n",
    "model = build_RNN_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights('./RNN_512_100/ckpt_10')\n",
    "\n",
    "#model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIET:\n",
      "Cousingrake.\n",
      "\n",
      "KATURONY:\n",
      "O heaven, I shalth.\n",
      "\n",
      "TRANIA:\n",
      "That merlpe in his slave your love of Gentlus sfillishal! Thou and Children! sild did that! I secried.\n",
      "\n",
      "GLOUCESTER:\n",
      "I careoou and in honours anove A reake.\n",
      "\n",
      "EDRUD:\n",
      "I down revented in envivel\n",
      "some the suthee proud to gran, that that that true!\n",
      "I seee to outhonest off, call chasselved ns weepings to soul:\n",
      "Canning.\n",
      "\n",
      "DUCHESI:\n",
      "I boint\n",
      "The ownil for and sumclus this his my dain;\n",
      "Thou mess.\n",
      "Thou folseth him, if your meant\n",
      "That I reath with it, of storely\n",
      "That that should shall's a comfretd,\n",
      "I ho, for still your daintly day?\n",
      "\n",
      "GAUNT:\n",
      "I talk:\n",
      "I have show fools to end, you'll\n",
      "That Till sin me sofides and repeace;\n",
      "Or, sir! Causer to joy seed; no well husband; I sids, to malla? thou speak of Biards is the happoner:\n",
      "Thou and so, but thou hast in a die!\n",
      "Will six, and throubled in my heaven thee see body'd the out, and you meet the romeffey'd the reass; my larged foot.\n",
      "\n",
      "LUCIO:\n",
      "But I away:\n",
      "Then.\n",
      "\n",
      "CORIOLANUS:\n",
      "Why, in these consuments and comesfoth t\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"JULIET\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
